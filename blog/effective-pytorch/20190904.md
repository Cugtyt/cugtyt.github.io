# 保证可复现

## Contact me

* Blog -> <https://cugtyt.github.io/blog/index>
* Email -> <cugtyt@qq.com>
* GitHub -> [Cugtyt@GitHub](https://github.com/Cugtyt)

> **本系列博客主页及相关见**[**此处**](https://cugtyt.github.io/blog/effective-pytorch/index)

---

来自[pytorch文档](https://pytorch.org/docs/stable/notes/randomness.html)

## PyTorch

使用`torch.manual_seed()`给所有设备(包括CPU and CUDA)固定随机数:

``` python
import torch
torch.manual_seed(0)
```

有一些Pytorch函数使用了CUDA的函数，可能导致不确定性。其中一类是原子操作，尤其是atomicAdd，使用它的地方有`torch.Tensor.index_add_()`, `torch.Tensor.scatter_add_()`, `torch.bincount()`。

有些运算使用atomicAdd会有问题，尤其是`torch.nn.functional.embedding_bag()`, `torch.nn.functional.ctc_loss()`，和很多的池化，填充，采样等。现在并没有简单的方法来确保他们是确定的。

## CuDNN

``` python
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```

使用确定模式可能出现性能问题，这取决于你的模型，像是每秒处理的批量等任务可能导致速度降低。

## Numpy

numpy也需要固定随机数。

``` python
import numpy as np
np.random.seed(0)
```