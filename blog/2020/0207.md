# 当机器学习性能不是很好时，你会如何优化？

## Contact me

* Blog -> <https://cugtyt.github.io/blog/index>
* Email -> <cugtyt@qq.com>
* GitHub -> [Cugtyt@GitHub](https://github.com/Cugtyt)

---

来自 百面机器学习 公众号

## 基于数据来改善性能

**获得更多的数据**。你能够拿到更多或者更高质量的数据么？对现代非线性机器学习模型如深度学习而言，数据越多，改进越多。

**创造更多数据**。如果你不能拿到更多数据，那么，你能创造出新的数据么？也许你可以填充或者重新排列现有数据，或者利用概率模型来产生新的数据。

**清洁你的数据**。你能否改善数据中的信号？也许可以纠正或删除一些缺失或错误的观测值，或者在合理范围外的离群点，从而提升数据质量。

**数据重新取样**。你能否对数据重新取样，以改变其大小或者分布？也许你可以用一个小得多的数据来实验，以提高实验的速度；或对某个特殊类型的观察值进行过采样/欠采样以使得它们更好地代表整个数据集。

**重新界定问题**。你能否改变你正试图解决的问题类型？重构数据，如回归，二项或多项分类，时间序列，异常检测，评分，推荐等问题类型。

**重新缩放数据**。你能否对数值型变量进行缩放处理？输入数据的归一化和标准化处理可以提升使用加权或距离度量的算法性能。

**转化数据**。你能否改变数据的分布形态？使得数据更服从高斯分布，或进行指数变换可能会暴露出数据更多的特征供算法学习。

**数据投影(映射)**。你能否将数据投影到一个更低维的空间？你可以用无监督的聚类或投影方法，创造一个新的压缩数据集代表。

**特征选择**。所有的输入变量是否同等重要？使用特征选择和衡量特征重要性的方法，可以创造出数据的新视角，供模型算法探索。

**特征工程**。 你能够创造或者增加新的特征？也许有的属性可以分解为多个新的值（比如类别，日期或字符串）或者属性可以聚集起来代表一个事件（如一个计数，二进制标志或统计信息）

## 基于算法

**重采样方法**。要用什么样的重采样方法来估计其在新数据上的能力？使用一种能够最好地利用现有数据的方法和参数设置。K折交叉验证法，利用其中的一折作为验证集可能是最佳操作。

**评价指标**。用什么样的指标来评价预测能力？选择能够最好地体现问题和专业需求的指标。不要任何问题一上来就看分类准确率。

**基线性能**。比较算法时，什么是基线性能？通过随机算法或零规则算法（预测均值或众数）来建立一个基线，并以此对所有算法进行排序。

**抽检线性算法**。什么样的线性算法能有好结果？线性方法通常更容易产生偏倚，也易于理解，能快速训练。如果能达到好效果，则更容易被选中。评估多个不同的线性方法。

**抽检非线性算法**:哪些非线性算法能有好结果？非线性算法通常要求更多数据，有更高的复杂性，但是能获得更好的性能。评估多个不同的非线性方法。

**从文献中偷师学艺**: 哪些文献报导的方法能很好地解决你的问题？也许你能从算法类型或传统方法的延伸中获取解决自己问题的灵感。

**标准参数设置**: 评估算法时，什么是标准的参数设置？每一个算法都有机会解决你的问题，这不是说在现有基础上死磕调参，而是说，每一种算法都需要把参数调好，才能在算法“大赛”中有胜出的机会

## 算法调参

**诊断**。对算法要做哪些诊断和回顾？也许可以回顾一下学习曲线，了解目前模型的状态是过拟合还是欠拟合，然后纠正它。不同的算法可能提供不同的可视化结果和诊断。检视算法得到正确预测结果和错误预测结果的样本。

**试试直觉**。你的直觉是什么？如果你琢磨参数的时间足够长，而反馈回路又很短，那么你会得到怎么调参的直觉。试一试，看看你遇到更大的难题时能不能再得到新的参数设置灵感。

**学习文献**。文献中用到了哪些参数，范围是多少？评估标准参数性能是调参的良好开端。

**随机搜索**。哪些参数可以用随机搜索？也许你可使用算法超参数的随机搜索，来发现那些你永远也想不到的参数设置。

**网格搜索**。哪些参数可以使用网格搜索？也许有一些标准超参数网格值，你可以拿来赋值，从而发现好的参数设置，重复这一过程，不断精调网格。

**最优化**。那些参数可以优化?也许有一些参数，如结构或者学习率，可以用直接搜索程序（如模式搜索）或随机优化（如遗传算法）来调整。

**交替实施**。算法有哪些其他的实施？也许其中的一个交替实施方法可以在同样的数据上得到更好的结果。每个算法都有无数的微决定由算法的使用者做出，其中的一些可能会影响到问题的解决。

**算法延伸**。哪些是常见的算法延伸？也许你可以通过评估常见的或标准的算法延伸而提高性能。这可能需要一些实施工作。

**算法定制**。对你的个案而言，需要做哪些算法定制？也许你可以为你的数据修饰算法，从损失函数，内部优化方法到算法的具体决定。

**联系专家**。对你的个案，专家们有什么算法推荐？给一个或多个算法领域的学术界专家写封简单的邮件，概述你的预测问题，以及你已经做出的尝试。这可能会让你获悉前沿工作，或者学术界不为你所知的新想法。

## 模型融合

**混合模型预测结果**。 你是否可以直接组合多个模型的预测结果？也许你可以使用同样的或不同的算法来搭建多个模型。对各自的预测结果取均值，或者众数。

**混合数据呈现方式**。你是否可以组合用不同数据呈现方法得到的模型预测结果？也许你使用了不同的问题投射方法，来训练性能良好的的算法，那么这些预测结果可以组合起来。

**混合数据样本**。你是否可以组合不同数据角度(特征)训练的模型？也许你可以创造训练样本的多个子样本来训练一个性能良好的算法，然后把结果组合起来。这叫做自助聚集（bootstrap aggregation）或者bagging，当各个模型的预测都很高明而方法各异（不相关）时，效果最好。

**纠正预测**。你是否可以纠正性能良好模型的预测？也许你可以明确地纠正预测结果，或者通过像boosting这样的方法来学习如何纠正预测错误。

**学习组合**。你能否使用新的模型，学习如何将多个性能良好的预测结果以最佳方式组合起来？这叫做堆栈（stacked generalization or stacking），当各子模型都很高明而方法各异时，通常能产生不错的结果，聚集模型就是各预测结果的简单加权线性模型。这个过程可以在多个层面上重复进行。
